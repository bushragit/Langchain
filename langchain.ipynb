{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30839,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "langchain",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bushragit/Langchain/blob/main/langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain_groq langchain langchain_core \"langchain-chroma>=0.1.2\" langchain_community sentence_transformers fastembed"
      ],
      "metadata": {
        "trusted": true,
        "id": "OmE9kigIY9xr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"]=getpass.getpass(\"Enter Key: \")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-27T11:24:09.536241Z",
          "iopub.execute_input": "2025-01-27T11:24:09.536598Z",
          "iopub.status.idle": "2025-01-27T11:25:39.694667Z",
          "shell.execute_reply.started": "2025-01-27T11:24:09.536553Z",
          "shell.execute_reply": "2025-01-27T11:25:39.693581Z"
        },
        "id": "1InA1Q-BY9xw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "model = ChatGroq(\n",
        "    model = \"llama3-8b-8192\",\n",
        "    temperature = 0,\n",
        "    max_tokens=None, #if None llm default\n",
        "    timeout=None,\n",
        "    max_retries=2\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-27T11:25:39.696886Z",
          "iopub.execute_input": "2025-01-27T11:25:39.697224Z",
          "iopub.status.idle": "2025-01-27T11:25:41.634525Z",
          "shell.execute_reply.started": "2025-01-27T11:25:39.697198Z",
          "shell.execute_reply": "2025-01-27T11:25:41.633616Z"
        },
        "id": "FCsRMP__Y9x5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.invoke(\"translate this sentence in urdu I am Beautiful\")\n",
        "print(result)\n",
        "print(result.content)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-27T11:25:41.635757Z",
          "iopub.execute_input": "2025-01-27T11:25:41.636301Z",
          "iopub.status.idle": "2025-01-27T11:25:41.980674Z",
          "shell.execute_reply.started": "2025-01-27T11:25:41.636262Z",
          "shell.execute_reply": "2025-01-27T11:25:41.979592Z"
        },
        "id": "vVQnkb9NY9x5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#now control prompt\n",
        "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-27T11:25:41.981732Z",
          "iopub.execute_input": "2025-01-27T11:25:41.982101Z",
          "iopub.status.idle": "2025-01-27T11:25:41.986142Z",
          "shell.execute_reply.started": "2025-01-27T11:25:41.982076Z",
          "shell.execute_reply": "2025-01-27T11:25:41.985228Z"
        },
        "id": "9OYuzaVUY9x6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "    SystemMessage(content=\"Solve this math problem\"),\n",
        "    HumanMessage(content=\"what is 2+65?\"),\n",
        "    AIMessage(content=\"The answer to 2+65 is 67.\"), #we actually send history to url llm\n",
        "    HumanMessage(content=\"what is 2*65?\")\n",
        "\n",
        "]\n",
        "\n",
        "result = model.invoke(messages)\n",
        "print(result)\n",
        "print(result.content)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-27T11:25:41.987099Z",
          "iopub.execute_input": "2025-01-27T11:25:41.987395Z",
          "iopub.status.idle": "2025-01-27T11:25:42.237701Z",
          "shell.execute_reply.started": "2025-01-27T11:25:41.987372Z",
          "shell.execute_reply": "2025-01-27T11:25:42.236755Z"
        },
        "id": "VpGouyIHY9x6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Context Length\n",
        "Context length refers to the amount of previous information or data that a model, such as a language model, can consider or use when generating a response, making predictions, or processing input.It determines how much of the previous conversation, text, or sequence the model can \"remember\" and use to generate the next word or make predictions."
      ],
      "metadata": {
        "id": "cF9y1i68Y9x7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-27T11:25:42.238853Z",
          "iopub.execute_input": "2025-01-27T11:25:42.239247Z",
          "iopub.status.idle": "2025-01-27T11:25:42.245481Z",
          "shell.execute_reply.started": "2025-01-27T11:25:42.23921Z",
          "shell.execute_reply": "2025-01-27T11:25:42.244393Z"
        },
        "id": "tozqmTsWY9x9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    (\"system\",\"you are a comedian who tells  jokes and you tell maximum 3 jokes\"),\n",
        "    (\"human\",\"tell me {count} joke about {topic}\")\n",
        "]\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
        "prompt = prompt_template.invoke({\"topic\":\"engineers\", \"count\": 3})\n",
        "print(prompt)\n",
        "result=model.invoke(prompt)\n",
        "print(result.content)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-27T11:25:42.248099Z",
          "iopub.execute_input": "2025-01-27T11:25:42.248513Z",
          "iopub.status.idle": "2025-01-27T11:25:42.592353Z",
          "shell.execute_reply.started": "2025-01-27T11:25:42.248472Z",
          "shell.execute_reply": "2025-01-27T11:25:42.591274Z"
        },
        "id": "jcKrIID1Y9x9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#multi step interaction using LLM\n",
        "from langchain.schema.output_parser import StrOutputParser"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-27T11:25:42.593655Z",
          "iopub.execute_input": "2025-01-27T11:25:42.594059Z",
          "iopub.status.idle": "2025-01-27T11:25:42.60192Z",
          "shell.execute_reply.started": "2025-01-27T11:25:42.594022Z",
          "shell.execute_reply": "2025-01-27T11:25:42.600761Z"
        },
        "id": "JKbO0uzTY9x-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#output of promptemplate is prompt\n",
        "chain = prompt_template | model | StrOutputParser()\n",
        "chain.invoke({\"topic\":\"engineers\", \"count\": 3})"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-27T11:25:42.603025Z",
          "iopub.execute_input": "2025-01-27T11:25:42.603344Z",
          "iopub.status.idle": "2025-01-27T11:25:42.925118Z",
          "shell.execute_reply.started": "2025-01-27T11:25:42.603319Z",
          "shell.execute_reply": "2025-01-27T11:25:42.924129Z"
        },
        "id": "FgGdZxY2Y9x_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CHAIN:"
      ],
      "metadata": {
        "id": "_twWnnuUY9yA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema.runnable import RunnableBranch, RunnableLambda"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-27T11:25:42.926302Z",
          "iopub.execute_input": "2025-01-27T11:25:42.926685Z",
          "iopub.status.idle": "2025-01-27T11:25:42.931876Z",
          "shell.execute_reply.started": "2025-01-27T11:25:42.926649Z",
          "shell.execute_reply": "2025-01-27T11:25:42.930889Z"
        },
        "id": "RrC-yH-WY9yA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "positive_feedback_template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"you are a helpfull assistant\"),\n",
        "    (\"human\",\n",
        "     \"generate a thank you email for the positive feedback: {feedback}.\"),\n",
        "])\n",
        "\n",
        "neutral_feedback_template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"you are a helpfull assistant\"),\n",
        "    (\"human\",\n",
        "     \"generate a request for more details on this neutral feedback from a user: {feedback}.\"),\n",
        "])\n",
        "\n",
        "negative_feedback_template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"you are a helpfull assistant\"),\n",
        "    (\"human\",\n",
        "     \"generate a apology note for user for this negative feedback : {feedback}.\"),\n",
        "])\n",
        "\n",
        "escalate_feedback_template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"you are a helpfull assistant\"),\n",
        "    (\"human\",\n",
        "     \"generate a msg to escalate this feedback to a human agent: {feedback}.\"),\n",
        "])\n",
        "\n",
        "classification_feedback_template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"you are a helpfull assistant\"),\n",
        "    (\"human\",\n",
        "     \"classify the sentiment of this  feedback as positive, negative, neutral or escalate and give response as one word in lower case: {feedback}.\"),\n",
        "])\n",
        "\n",
        "classification_chain=(\n",
        "    classification_feedback_template|model|StrOutputParser()\n",
        ")\n",
        "\n",
        "\n",
        "branches = RunnableBranch(\n",
        "    (\n",
        "        lambda x: \"positive\" in x,\n",
        "        positive_feedback_template|model|StrOutputParser()\n",
        "\n",
        "    ),\n",
        "    (\n",
        "        lambda x: \"negative\" in x,\n",
        "        negative_feedback_template|model|StrOutputParser()\n",
        "    ),\n",
        "    (\n",
        "        lambda x: \"neutral\" in x,\n",
        "        neutral_feedback_template|model|StrOutputParser()\n",
        "    ),\n",
        "     escalate_feedback_template|model|StrOutputParser()\n",
        ")\n",
        "\n",
        "#when input enter what to do step by step\n",
        "#define chain of classification\n",
        "\n",
        "\n",
        "#final chain\n",
        "chain = classification_chain | branches\n",
        "\n",
        "#result\n",
        "review=\"the movie is great\"\n",
        "result=chain.invoke({\"feedback\": review})\n",
        "print(result)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-27T11:49:26.293016Z",
          "iopub.execute_input": "2025-01-27T11:49:26.293368Z",
          "iopub.status.idle": "2025-01-27T11:49:26.96541Z",
          "shell.execute_reply.started": "2025-01-27T11:49:26.293343Z",
          "shell.execute_reply": "2025-01-27T11:49:26.964397Z"
        },
        "id": "73ocI7TvY9yB"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}